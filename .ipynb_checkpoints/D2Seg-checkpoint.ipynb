{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0421db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, cv2, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce8ef94",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "COCO-InstanceSegmentation/faster_rcnn_R_101_FPN_3x.yaml not available in Model Zoo!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_zoo\n\u001b[0;32m     15\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_cfg()\n\u001b[1;32m---> 16\u001b[0m cfg\u001b[38;5;241m.\u001b[39mmerge_from_file(\u001b[43mmodel_zoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOCO-InstanceSegmentation/faster_rcnn_R_101_FPN_3x.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mROI_HEADS\u001b[38;5;241m.\u001b[39mSCORE_THRESH_TEST \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m   \u001b[38;5;66;03m# set a custom testing threshold\u001b[39;00m\n\u001b[0;32m     18\u001b[0m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mROI_HEADS\u001b[38;5;241m.\u001b[39mNUM_CLASSES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\asus\\pictures\\detectron\\detectron2\\detectron2\\model_zoo\\model_zoo.py:143\u001b[0m, in \u001b[0;36mget_config_file\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m    139\u001b[0m cfg_file \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mresource_filename(\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetectron2.model_zoo\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigs\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_path)\n\u001b[0;32m    141\u001b[0m )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cfg_file):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not available in Model Zoo!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config_path))\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfg_file\n",
      "\u001b[1;31mRuntimeError\u001b[0m: COCO-InstanceSegmentation/faster_rcnn_R_101_FPN_3x.yaml not available in Model Zoo!"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "# cfg.MODEL.WEIGHTS = \"./OutputModels/model_final.pth\"\n",
    "cfg.MODEL.WEIGHTS = \"./OutputModelsSegmentation/model_final.pth\"\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "upload_dir = \"./uploadeImages/\"\n",
    "predict_dir = \"./SegImages/\"\n",
    "os.makedirs(upload_dir,exist_ok=True)\n",
    "os.makedirs(predict_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c439ef17",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'val' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mregister_coco_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/val.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/val\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m val_metadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m val_dicts \u001b[38;5;241m=\u001b[39m DatasetCatalog\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\asus\\pictures\\detectron\\detectron2\\detectron2\\data\\datasets\\coco.py:500\u001b[0m, in \u001b[0;36mregister_coco_instances\u001b[1;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[0;32m    504\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[0;32m    505\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[0;32m    506\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\asus\\pictures\\detectron\\detectron2\\detectron2\\data\\catalog.py:37\u001b[0m, in \u001b[0;36m_DatasetCatalog.register\u001b[1;34m(self, name, func)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    func (callable): a callable which takes no arguments and returns a list of dicts.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m        It must return the same results if called multiple times.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m callable(func), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must register a function with `DatasetCatalog.register`!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m[name] \u001b[38;5;241m=\u001b[39m func\n",
      "\u001b[1;31mAssertionError\u001b[0m: Dataset 'val' is already registered!"
     ]
    }
   ],
   "source": [
    "register_coco_instances(\"val\",{},\"Data/val.json\",\"Data/val\")\n",
    "\n",
    "val_metadata = MetadataCatalog.get('val')\n",
    "val_dicts = DatasetCatalog.get('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c020e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'Data/val\\\\ISIC_0238871.jpg',\n",
       " 'height': 300,\n",
       " 'width': 300,\n",
       " 'image_id': 0,\n",
       " 'annotations': [{'iscrowd': 0,\n",
       "   'bbox': [108.0, 132.0, 43.0, 61.0],\n",
       "   'category_id': 0,\n",
       "   'segmentation': [[108.79010494752623,\n",
       "     141.22938530734632,\n",
       "     114.63718140929535,\n",
       "     168.9655172413793,\n",
       "     129.02998500749626,\n",
       "     185.60719640179911,\n",
       "     146.12143928035982,\n",
       "     193.7031484257871,\n",
       "     151.51874062968517,\n",
       "     179.46026986506746,\n",
       "     144.3223388305847,\n",
       "     166.4167916041979,\n",
       "     132.1784107946027,\n",
       "     147.07646176911544,\n",
       "     126.78110944527737,\n",
       "     132.68365817091455,\n",
       "     116.43628185907048,\n",
       "     133.43328335832084]],\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5957210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Pictures\\Detectron\\env\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(val_dicts[0][\"file_name\"])\n",
    "imgarray = np.array(img)[:, :, ::-1]\n",
    "res = predictor(imgarray)\n",
    "\n",
    "filename = val_dicts[0][\"file_name\"].split(\"\\\\\")[-1:][0]\n",
    "predict_fle = os.path.join(predict_dir,filename)\n",
    "v = Visualizer(img, metadata=val_metadata, scale=0.8)\n",
    "v = v.draw_instance_predictions(res[\"instances\"].to(\"cpu\"))\n",
    "cv2.imwrite(predict_fle,v.get_image()[:, :, ::-1]) #save predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04578a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': Instances(num_instances=0, image_height=300, image_width=300, fields=[pred_boxes: Boxes(tensor([], size=(0, 4))), scores: tensor([]), pred_classes: tensor([], dtype=torch.int64)])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70247211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/val\\ISIC_6404049A3.jpg\n",
      "Data/val\\ISIC_9900262.jpg\n",
      "Data/val\\ISIC_9944931.jpg\n",
      "Data/val\\ISIC_0264941.jpg\n",
      "Data/val\\ISIC_9900191A4.jpg\n",
      "Data/val\\ISIC_9870885.jpg\n",
      "Data/val\\ISIC_9770677.jpg\n",
      "Data/val\\ISIC_9919143.jpg\n",
      "Data/val\\ISIC_9927490.jpg\n",
      "Data/val\\ISIC_9785077A4.jpg\n"
     ]
    }
   ],
   "source": [
    "for d in random.sample(val_dicts,10):\n",
    "    print(d[\"file_name\"])\n",
    "    img = Image.open(d[\"file_name\"])\n",
    "    imgarray = np.array(img)[:, :, ::-1]\n",
    "    res = predictor(imgarray)\n",
    "\n",
    "    filename = val_dicts[0][\"file_name\"].split(\"\\\\\")[-1:][0]\n",
    "    predict_fle = os.path.join(predict_dir,filename)\n",
    "    v = Visualizer(img, metadata=val_metadata, scale=0.8)\n",
    "    v = v.draw_instance_predictions(res[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imwrite(predict_fle,v.get_image()[:, :, ::-1]) #save predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8299a25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(val_dicts[2][\"file_name\"])\n",
    "imgarray = np.array(img)[:, :, ::-1]\n",
    "res = predictor(imgarray)\n",
    "\n",
    "filename = val_dicts[2][\"file_name\"].split(\"\\\\\")[-1:][0]\n",
    "v = Visualizer(img, metadata=val_metadata, scale=0.8)\n",
    "v = v.draw_instance_predictions(res[\"instances\"].to(\"cpu\"))\n",
    "cv2.imwrite(f\"{predict_dir}{filename}\",v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e09c9472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 10, 47, 65,  3, 58])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7df664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in np.random.randint(0,len(val_dicts),6):\n",
    "    img = Image.open(val_dicts[ind][\"file_name\"])\n",
    "    imgarray = np.array(img)[:, :, ::-1]\n",
    "    res = predictor(imgarray)\n",
    "\n",
    "    filename = val_dicts[ind][\"file_name\"].split(\"\\\\\")[-1:][0]\n",
    "    v = Visualizer(img, metadata=val_metadata, scale=0.8)\n",
    "    v = v.draw_instance_predictions(res[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imwrite(f\"{predict_dir}{filename}\",v.get_image()[:, :, ::-1])\n",
    "    plt.imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f15d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
